{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ffilm_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoMurase/Learning_my_interest/blob/master/Ffilm_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AW2aWDAT8wI",
        "colab_type": "code",
        "outputId": "c89691e9-638a-4248-8e08-e4136d3b03f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqNne6Z4JnVn",
        "colab_type": "code",
        "outputId": "d033ae4b-3cef-4106-9b3f-0a1f4bbdaf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!pip install imagehash"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.6/dist-packages (4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imagehash) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imagehash) (1.17.4)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.6/dist-packages (from imagehash) (1.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imagehash) (4.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imagehash) (1.3.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imagehash) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_IWwheRrQ3Z",
        "colab_type": "code",
        "outputId": "b83b6df7-a0bc-4216-d542-77946a5ad299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dZhx0PkAXOf",
        "colab_type": "code",
        "outputId": "27b70f41-5f93-445e-ad87-5fdb52d6797d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK0L_i-Yrehp",
        "colab_type": "code",
        "outputId": "41e3d165-18ae-483c-edc6-a9adf1c537f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExelNrT6riDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip input.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pacxKVs9UDB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "label = pd.read_csv('/content/drive/My Drive/ffilm/input/train_labels.csv',names=('img','age'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug2ylSTIU6M5",
        "colab_type": "code",
        "outputId": "4716eab1-8da1-4d3f-aa5a-9403701e4a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "label.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0001.png</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_0002.png</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_0003.png</td>\n",
              "      <td>1994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_0004.png</td>\n",
              "      <td>2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_0005.png</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              img   age\n",
              "0  train_0001.png  2012\n",
              "1  train_0002.png  2003\n",
              "2  train_0003.png  1994\n",
              "3  train_0004.png  2014\n",
              "4  train_0005.png  2003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajT4ZkliaZbQ",
        "colab_type": "code",
        "outputId": "a1c60fbc-2cc1-4dcd-b3cd-d538b171441c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "ax = label['age'].value_counts().plot(kind='bar', figsize=(12, 5))\n",
        "ax.set_xlabel('age')\n",
        "ax.set_ylabel('Count')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAFMCAYAAADr8CtDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBbUkSZLUwP8HHWfHfslvi+IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJR5dr4Ap_KA",
        "colab_type": "code",
        "outputId": "8d2132e7-bd75-45b6-ff3c-5d0f7403e3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label['age'].value_counts().sum()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6686"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOoQ5qFTMNwW",
        "colab_type": "code",
        "outputId": "f22d1d8c-419a-4149-c248-2857baec3e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels = label['age'].values\n",
        "train_labels"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2012, 2003, 1994, ..., 1988, 1999, 2004])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3XU7Q6FtV5x",
        "colab_type": "code",
        "outputId": "6d1bb9fb-7668-45b6-b53d-3619dd12f660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        " \"\"\" #画像フォルダにある画像をndarrayとして読み込む\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "\n",
        "#image  array size\n",
        "img_size = (224,224)\n",
        "#load images Folder\n",
        "dir_name = '/content/drive/My Drive/ffilm/input/train_images'\n",
        "#File type\n",
        "file_type  = 'png'\n",
        "\n",
        "#lフォルダ内のファイルパスをリスト化\n",
        "img_list = glob.glob(dir_name + '/*.' + file_type)\n",
        "#保存先の配列を確保\n",
        "temp_img_array_list = []\n",
        "\n",
        "#ファイルパスのリストを元に画像を配列化\n",
        "for img in img_list:\n",
        "    #画像を224x224にリサイズ\n",
        "    temp_img = load_img(img,grayscale=False,target_size=(img_size))\n",
        "    #PIL形式からNumpy配列に変換と正規化\n",
        "    temp_img_array = img_to_array(temp_img) /255\n",
        "    #変換したNumpy配列を末尾に追加\n",
        "    temp_img_array_list.append(temp_img_array)\n",
        "\n",
        "#Numpy配列をリスト化(*,224,224,3)\n",
        "train_img_array_list = np.array(temp_img_array_list)\n",
        "\n",
        "#save np.array\n",
        "np.savez(dir_name+'.npz',train_img_array_list)\n",
        "\"\"\""
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" #画像フォルダにある画像をndarrayとして読み込む\\n\\nimport glob\\nimport numpy as np\\nfrom keras.preprocessing.image import load_img,img_to_array\\n\\n#image  array size\\nimg_size = (224,224)\\n#load images Folder\\ndir_name = '/content/drive/My Drive/ffilm/input/train_images'\\n#File type\\nfile_type  = 'png'\\n\\n#lフォルダ内のファイルパスをリスト化\\nimg_list = glob.glob(dir_name + '/*.' + file_type)\\n#保存先の配列を確保\\ntemp_img_array_list = []\\n\\n#ファイルパスのリストを元に画像を配列化\\nfor img in img_list:\\n   #画像を224x224にリサイズ\\n   temp_img = load_img(img,grayscale=False,target_size=(img_size))\\n   #PIL形式からNumpy配列に変換と正規化\\n   temp_img_array = img_to_array(temp_img) /255\\n   #変換したNumpy配列を末尾に追加\\n   temp_img_array_list.append(temp_img_array)\\n\\n#Numpy配列をリスト化(*,224,224,3)\\ntrain_img_array_list = np.array(temp_img_array_list)\\n\\n#save np.array\\nnp.savez(dir_name+'.npz',train_img_array_list)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G7FeOVPwS51",
        "colab_type": "code",
        "outputId": "60ed58d6-ed1c-4972-dcba-f6b6730d6119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "#load images Folder\n",
        "dir_name = '/content/drive/My Drive/ffilm/input/test_images'\n",
        "\n",
        "#lフォルダ内のファイルパスをリスト化\n",
        "img_list = glob.glob(dir_name + '/*.' + file_type)\n",
        "#保存先の配列を確保\n",
        "temp_img_array_list = []\n",
        "\n",
        "#ファイルパスのリストを元に画像を配列化\n",
        "for img in img_list:\n",
        "    #画像を224x224にリサイズ\n",
        "    temp_img = load_img(img,grayscale=False,target_size=(img_size))\n",
        "    #PIL形式からNumpy配列に変換と正規化\n",
        "    temp_img_array = img_to_array(temp_img) /255\n",
        "    #変換したNumpy配列を末尾に追加\n",
        "    temp_img_array_list.append(temp_img_array)\n",
        "\n",
        "#Numpy配列をリスト化(*,224,224,3)\n",
        "test_img_array_list = np.array(temp_img_array_list)\n",
        "\n",
        "#save np.array\n",
        "np.savez(dir_name+'.npz',test_img_array_list)\n",
        "\"\"\""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#load images Folder\\ndir_name = '/content/drive/My Drive/ffilm/input/test_images'\\n\\n#lフォルダ内のファイルパスをリスト化\\nimg_list = glob.glob(dir_name + '/*.' + file_type)\\n#保存先の配列を確保\\ntemp_img_array_list = []\\n\\n#ファイルパスのリストを元に画像を配列化\\nfor img in img_list:\\n    #画像を224x224にリサイズ\\n    temp_img = load_img(img,grayscale=False,target_size=(img_size))\\n    #PIL形式からNumpy配列に変換と正規化\\n    temp_img_array = img_to_array(temp_img) /255\\n    #変換したNumpy配列を末尾に追加\\n    temp_img_array_list.append(temp_img_array)\\n\\n#Numpy配列をリスト化(*,224,224,3)\\ntest_img_array_list = np.array(temp_img_array_list)\\n\\n#save np.array\\nnp.savez(dir_name+'.npz',test_img_array_list)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qf1QfHjxgRy",
        "colab_type": "code",
        "outputId": "48d52710-5cd5-4a63-c8bc-5f4cfa97fa47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\" import google.colab\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.cuda\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torch.utils.data as dataset\n",
        "import torchvision.models as models\n",
        "\n",
        "import albumentations\n",
        "import imagehash\n",
        "import argparse\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import csv\n",
        "\n",
        "RANDOM_SEED = 2019\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" import google.colab\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom PIL import Image\\nfrom sklearn.model_selection import train_test_split\\n\\nimport torch.cuda\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torch.autograd as autograd\\nimport torch.utils.data as dataset\\nimport torchvision.models as models\\n\\nimport albumentations\\nimport imagehash\\nimport argparse\\nimport os\\nimport tqdm\\nimport random\\nimport csv\\n\\nRANDOM_SEED = 2019\\n\\nrandom.seed(RANDOM_SEED)\\nos.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\\nnp.random.seed(RANDOM_SEED)\\ntorch.manual_seed(RANDOM_SEED)\\ntorch.cuda.manual_seed(RANDOM_SEED)\\n\\ntorch.torch.backends.cudnn.benchmark = True\\ntorch.torch.backends.cudnn.enabled = True\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUCT1pCSwfVI",
        "colab_type": "code",
        "outputId": "21c4b866-ba92-4672-a71c-fcffcbdb4582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "DATA_DIR = '/content/drive/My Drive/ffilm/input/'\n",
        "#train_labels = np.load(os.path.join(DATA_DIR, 'ukiyoe-train-labels.npz'))['arr_0']\n",
        "train_images = np.load(DATA_DIR+'train_images.npy')\n",
        "test_images = np.load(DATA_DIR+'test_images.npz'))['arr_0']\n",
        "print('train-labels: shape={}, dtype={}'.format(train_labels.shape, train_labels.dtype))\n",
        "print('train-images: shape={}, dtype={}'.format(train_images.shape, train_images.dtype))\n",
        "print('test-images: shape={}, dtype={}'.format(test_images.shape, test_images.dtype))\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nDATA_DIR = '/content/drive/My Drive/ffilm/input/'\\n#train_labels = np.load(os.path.join(DATA_DIR, 'ukiyoe-train-labels.npz'))['arr_0']\\ntrain_images = np.load(DATA_DIR+'train_images.npy')\\ntest_images = np.load(DATA_DIR+'test_images.npz'))['arr_0']\\nprint('train-labels: shape={}, dtype={}'.format(train_labels.shape, train_labels.dtype))\\nprint('train-images: shape={}, dtype={}'.format(train_images.shape, train_images.dtype))\\nprint('test-images: shape={}, dtype={}'.format(test_images.shape, test_images.dtype))\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mhwTlxr_xBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob \n",
        "import os.path as osp \n",
        "import random \n",
        "import numpy as np \n",
        "import json \n",
        "from PIL import Image \n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.optim as optim \n",
        "import torch.utils.data as data \n",
        "import torchvision \n",
        "from torchvision import models , transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrdKwNaots9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import glob \n",
        "import os.path as osp \n",
        "import random \n",
        "import numpy as np \n",
        "import json \n",
        "from PIL import Image \n",
        "from tqdm import tqdm \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.optim as optim \n",
        "import torch.utils.data as data \n",
        "import torchvision \n",
        "from torchvision import models , transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zkJx1Sh89Sc",
        "colab_type": "code",
        "outputId": "62b20371-6ed5-4bb0-d43a-e06539733e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#画像のファイルパスを作成する\n",
        "def make_datapath_list(phase='train'):\n",
        "  rootpath ='/content/drive/My Drive/ffilm/input/'\n",
        "  #age_list=label['age'].values\n",
        "  target_path = osp.join(rootpath+phase+'/*.png')\n",
        "  print(target_path)\n",
        "  \n",
        "  path_list = []\n",
        "  \n",
        "  #globを利用してサブディレクトリまでパスを取得する\n",
        "  for path in glob.glob(target_path):\n",
        "    path_list.append(path)\n",
        "  \n",
        "  return path_list\n",
        "\n",
        "#実行\n",
        "train_list = make_datapath_list(phase='train_images')\n",
        "test_list = make_datapath_list(phase='test_images')\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ffilm/input/train_images/*.png\n",
            "/content/drive/My Drive/ffilm/input/test_images/*.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boivxwAU9AsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageTransform():\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(\n",
        "                    resize, scale=(0.5, 1.0)),  # データオーギュメンテーション\n",
        "                transforms.RandomHorizontalFlip(),  # データオーギュメンテーション\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize(mean, std)  # 標準化\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(resize),  # リサイズ\n",
        "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize(mean, std)  # 標準化\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        \n",
        "        return self.data_transform[phase](img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwSt4P5UESn7",
        "colab_type": "code",
        "outputId": "d2f57bc3-9965-4f52-ed97-85defdf2630b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import cv2\n",
        "\n",
        "im = cv2.imread('/content/drive/My Drive/ffilm/input/train_images/train_0100.png')\n",
        "\n",
        "print(type(im))\n",
        "print(im.shape)\n",
        "print(type(im.shape))\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(256, 256, 3)\n",
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLCVdIq4E_0q",
        "colab_type": "code",
        "outputId": "eeef7461-e22f-4287-d396-cb96be6f0a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "size = 224\n",
        "mean = (0.485,0.456,0.406)\n",
        "std = (0.229,0.224,0.225)\n",
        "\n",
        "#Datasetの作成\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  \"\"\"\n",
        "  PytorchのDatasetクラスを継承\n",
        "  \"\"\"\n",
        "  def __init__(self,file_list, labels,transform=None,phase='train'):\n",
        "    self.labels= labels\n",
        "    self.file_list = file_list\n",
        "    self.transform = transform \n",
        "    self.phase = phase\n",
        "    \n",
        "  def __len__(self):\n",
        "    \"\"\"画像の枚数を返す\"\"\"\n",
        "    return len(self.file_list)\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    '''\n",
        "    前処理をした画像のTensoor形式のデータとラベルを取得\n",
        "    '''\n",
        "    img_path = self.file_list[index]\n",
        "    img = Image.open(img_path)\n",
        "    \n",
        "    #画像の前処理を実施\n",
        "    img_transformed = self.transform(\n",
        "        img, self.phase\n",
        "    ) #torch.Size([3,224,224])\n",
        "    \n",
        "    #画像のラベルをファイル名から抜き出す\n",
        "    #if self.phase == 'train':\n",
        "    #  label = img_path[54:57] #train/の後の　catかdogを入れたい\n",
        "    #elif self.phase == 'val':\n",
        "    #  label = img_path[52:55] #val/の後の　catかdogを入れたい\n",
        "    \n",
        "    #ラベルを数値に変換\n",
        "    #if label == 'cat':\n",
        "    #  label = 0\n",
        "    #elif label == 'dog':\n",
        "    #  label = 1\n",
        "    label = self.labels[index] -1979\n",
        "      \n",
        "    return img_transformed, label\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(\n",
        "  train_list ,train_labels, test_size=0.5, random_state=4869\n",
        "  )\n",
        "\n",
        " #実行\n",
        "train_dataset = Dataset(\n",
        "      file_list = train_x, labels=train_y, transform=ImageTransform(size,mean,std),phase='train'\n",
        "    )\n",
        "val_dataset = Dataset(\n",
        "      file_list = valid_x, labels=valid_y, transform=ImageTransform(size,mean,std),phase='val'\n",
        "    )\n",
        "    \n",
        "#indexの確認\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])\n",
        "#print(len('/content/drive/My Drive/ffilm/input/train_images/'))\n",
        "#print(len('/content/drive/My Drive/ffilm/input/train_images/'))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPNip_v-qNwZ",
        "colab_type": "code",
        "outputId": "432ae897-1716-4cbd-ffb6-bd91f865ddec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLcugsrwqYtX",
        "colab_type": "code",
        "outputId": "6def5645-b35d-42e2-dce5-7f3384866a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(val_dataset)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oh3ko1gZciV",
        "colab_type": "code",
        "outputId": "eb7fb3d3-4e21-4272-e301-d60db625ded4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 1.4440,  1.4440,  1.4783,  ...,  1.7009,  1.0331,  0.6392],\n",
              "          [ 1.5639,  1.6324,  1.5810,  ...,  2.0777,  1.8379,  1.6495],\n",
              "          [ 1.7180,  1.7180,  1.7352,  ...,  2.2318,  2.1975,  2.1975],\n",
              "          ...,\n",
              "          [-1.8953, -1.8268, -1.8439,  ..., -1.3473, -1.4672, -1.6042],\n",
              "          [-1.8439, -1.8439, -1.8439,  ..., -1.4843, -1.5014, -1.4843],\n",
              "          [-1.8439, -1.8268, -1.8610,  ..., -1.1247, -1.1075, -1.0562]],\n",
              " \n",
              "         [[-1.0378, -1.0378, -1.0553,  ...,  1.2381,  0.4678,  0.0476],\n",
              "          [-0.9153, -0.8452, -0.9503,  ...,  1.6758,  1.3957,  1.2906],\n",
              "          [-0.7227, -0.7227, -0.7227,  ...,  1.9384,  1.9384,  2.0609],\n",
              "          ...,\n",
              "          [-1.7556, -1.6681, -1.6856,  ..., -0.6877, -0.7577, -0.8978],\n",
              "          [-1.6856, -1.7031, -1.7381,  ..., -0.7927, -0.7927, -0.7752],\n",
              "          [-1.6856, -1.7031, -1.7731,  ..., -0.3901, -0.3725, -0.3025]],\n",
              " \n",
              "         [[-0.7238, -0.7064, -0.6890,  ...,  0.6879, -0.1835, -0.6018],\n",
              "          [-0.5495, -0.4450, -0.5321,  ...,  1.2457,  0.9145,  0.8274],\n",
              "          [-0.2707, -0.2707, -0.2707,  ...,  1.5594,  1.5594,  1.6988],\n",
              "          ...,\n",
              "          [-1.5256, -1.4559, -1.4733,  ..., -1.3164, -1.4036, -1.5256],\n",
              "          [-1.4733, -1.4907, -1.5081,  ..., -1.6302, -1.6302, -1.6127],\n",
              "          [-1.4384, -1.4907, -1.5430,  ..., -1.4907, -1.4733, -1.4384]]]), 39)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twXlkiHILpeK",
        "colab_type": "code",
        "outputId": "557d9460-799b-424a-f5e2-ead417163866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# ミニバッチのサイズを指定\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 辞書型変数にまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader,\"val\": val_dataloader}\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
        "inputs, labels = next(\n",
        "    batch_iterator)  # 1番目の要素を取り出す\n",
        "print(inputs.size())\n",
        "print(labels)\n",
        "print(len(labels))\n",
        "\n",
        "\n",
        "batch_iterator = iter(dataloaders_dict[\"val\"])  # イテレータに変換\n",
        "inputs, labels = next(\n",
        "    batch_iterator)  # 1番目の要素を取り出す\n",
        "print(inputs.size())\n",
        "print(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([31, 19, 29, 20, 21, 20, 35, 27, 18, 25,  7, 17, 13,  3, 10, 20, 10, 24,\n",
            "        21, 34, 15,  5, 15, 22, 32, 39, 10, 16, 17, 33, 34,  9])\n",
            "32\n",
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([15,  6,  7, 26, 18, 39, 13, 11, 25, 13,  3, 21, 39, 12, 14, 11, 24, 16,\n",
            "        19, 23, 29, 10, 17, 26, 12, 23, 38, 16, 10, 31, 24, 34])\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYU6q4baIm9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習済みのVGG-16モデルをロード\n",
        "# VGG-16モデルのインスタンスを生成\n",
        "use_pretrained = True  # 学習済みのパラメータを使用\n",
        "net = models.vgg16(pretrained=use_pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVBF0KDGIoRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaRlIBuxT6xp",
        "colab_type": "code",
        "outputId": "e4b2c155-fe78-4921-d964-1c2b9db59ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "# VGG16の最後の出力層の出力ユニットを付け替える\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=40)\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRCBze0FXoUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIBe8IneUNCL",
        "colab_type": "code",
        "outputId": "5ec0b06c-4726-4295-a83f-2b96a7e20315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#転移学習で学習させるパラメータを変数params_to_updateに格納する\n",
        "params_to_update = []\n",
        "\n",
        "# 学習させるパラメータ名\n",
        "update_param_names = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "for name, param in net.named_parameters():\n",
        "    if name in update_param_names:\n",
        "        param.requires_grad = True\n",
        "        params_to_update.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# params_to_updateの中身を確認\n",
        "print(\"-----------\")\n",
        "print(params_to_update)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier.6.weight\n",
            "classifier.6.bias\n",
            "-----------\n",
            "[Parameter containing:\n",
            "tensor([[-0.0060,  0.0136,  0.0057,  ..., -0.0002,  0.0108, -0.0049],\n",
            "        [ 0.0007, -0.0145, -0.0086,  ...,  0.0035, -0.0110,  0.0140],\n",
            "        [ 0.0037, -0.0047,  0.0132,  ...,  0.0069, -0.0115, -0.0025],\n",
            "        ...,\n",
            "        [-0.0090, -0.0107,  0.0089,  ..., -0.0102, -0.0120,  0.0060],\n",
            "        [ 0.0040,  0.0003, -0.0079,  ...,  0.0042,  0.0124,  0.0110],\n",
            "        [-0.0077,  0.0051,  0.0039,  ..., -0.0092, -0.0021,  0.0049]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0045, -0.0057,  0.0062, -0.0138, -0.0126, -0.0122,  0.0084, -0.0153,\n",
            "        -0.0003, -0.0112, -0.0028,  0.0037,  0.0138,  0.0003, -0.0088,  0.0012,\n",
            "        -0.0010,  0.0077,  0.0008,  0.0057,  0.0084,  0.0129,  0.0037,  0.0110,\n",
            "        -0.0129, -0.0079,  0.0078,  0.0070,  0.0004,  0.0075, -0.0094,  0.0097,\n",
            "        -0.0149,  0.0102,  0.0034, -0.0058, -0.0033,  0.0034, -0.0010, -0.0084],\n",
            "       requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT0fdo78UbJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 最適化手法の設定\n",
        "optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apZwD7oQUd_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "    # 初期設定\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "              \n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "                    \n",
        "  \n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イタレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  \n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TkbMpv2Ukka",
        "colab_type": "code",
        "outputId": "9904a01d-f7ce-4c47-cab8-4a6a224bce9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 学習・検証を実行する\n",
        "from __future__ import division\n",
        "num_epochs=2\n",
        "\n",
        "\n",
        "model = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "Epoch 1/2\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 105/105 [00:32<00:00,  3.83it/s]\n",
            "  0%|          | 0/105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 3.5459 Acc: 0.0440\n",
            "Epoch 2/2\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 105/105 [00:32<00:00,  3.89it/s]\n",
            "  0%|          | 0/105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 3.5013 Acc: 0.0730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 105/105 [00:32<00:00,  3.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 3.5422 Acc: 0.0517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMIPuwrsUoIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = net.state_dict()\n",
        "torch.save(params,\"net_1221.prm\",pickle_protocol=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmwHMOhngqTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = net.state_dict()\n",
        "torch.save(params,\"/content/drive/My Drive/ffilm/input/net_1221.prm\",pickle_protocol=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDPP0gZabnTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijy-hR00j0dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####予測結果の返し方がわからない"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlDap433j0ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X75yfJBnf1cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "8cd6f1d5-ae9c-449d-ed95-d25a53656433"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "test_iter = iter(test_loader)\n",
        "inputs, labels = test_iter.next()\n",
        "outputs = net(Variable(inputs))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-7f4deb66c660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE2ezoB5ZER2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations as albu\n",
        "from albumentations import pytorch as AT\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "\n",
        "\n",
        "path='/content/drive/My Drive/ffilm/input/'\n",
        "\n",
        "class FFDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame = None, datatype: str = 'train',\n",
        "                 transforms=albu.Compose([albu.HorizontalFlip(), AT.ToTensor()]), ):\n",
        "\n",
        "        self.df = df\n",
        "        self.data = df['id']\n",
        "        self.label = df['label']\n",
        "        if datatype != 'test':\n",
        "            self.data_folder = f\"{path}/train_images\"\n",
        "        else:\n",
        "            self.data_folder = f\"{path}/test_images\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.data[idx]\n",
        "        image_path = os.path.join(self.data_folder, image_name)\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        augmented = self.transforms(image=img)\n",
        "        img = augmented['image']\n",
        "        label = self.label[idx]\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "# train用のデータ拡張\n",
        "data_transforms = albu.Compose([\n",
        "    albu.Resize(img_height, img_width),\n",
        "    albu.HorizontalFlip(p=0.5),\n",
        "    albu.VerticalFlip(p=0.5),\n",
        "    albu.RandomBrightnessContrast(p=0.3),\n",
        "    albu.RandomGamma(gamma_limit=(85, 115), p=0.3),\n",
        "    albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.10, rotate_limit=45, p=0.5),\n",
        "    albu.Normalize(),\n",
        "    AT.ToTensor()\n",
        "])\n",
        "\n",
        "# test用のデータ拡張\n",
        "data_transforms_test = albu.Compose([\n",
        "    albu.Resize(img_height, img_width),\n",
        "    albu.Normalize(),\n",
        "    AT.ToTensor()\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ajVvNvNZTeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/ffilm/input/sample_submission.csv', header=None, names=[\"id\", \"label\"])\n",
        "\n",
        "test_dataset = FFDataset(df=submission, datatype='test', transforms=data_transforms_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDpV2BjKetJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f0a8e8a-3364-49f4-ea72-6e2f9ea03cb3"
      },
      "source": [
        "test_loader"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f87574c7828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCUzavhsNHCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d64b08dc-1f4b-4746-ef39-1538c2c02cca"
      },
      "source": [
        "#train_model.eval()\n",
        "net(data_transform_test)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-8eb60297cd11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_transform_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_transform_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T790y_Z2Nadi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = sorted(list(train['label'].unique()))\n",
        "pred_list = []\n",
        "for i in range(n_test):\n",
        "    probabilities = torch.softmax(torch.from_numpy(predictions[i]), dim=0)\n",
        "    label = probabilities.argmax().item()\n",
        "    pred_list.append(class_names[label] + 1979)\n",
        "\n",
        "submission['label'] = pred_list\n",
        "submission.to_csv('submission.csv', header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM7lsBQDNVPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}